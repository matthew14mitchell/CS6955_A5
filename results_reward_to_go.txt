Using simplest formulation of policy gradient.

epoch:   0 	 loss: 9.372 	 return: 20.533 	 ep_len: 20.533
epoch:   1 	 loss: 9.703 	 return: 21.229 	 ep_len: 21.229
epoch:   2 	 loss: 11.490 	 return: 25.531 	 ep_len: 25.531
epoch:   3 	 loss: 13.674 	 return: 29.775 	 ep_len: 29.775
epoch:   4 	 loss: 15.128 	 return: 32.532 	 ep_len: 32.532
epoch:   5 	 loss: 15.685 	 return: 35.807 	 ep_len: 35.807
epoch:   6 	 loss: 20.075 	 return: 40.902 	 ep_len: 40.902
epoch:   7 	 loss: 18.584 	 return: 43.730 	 ep_len: 43.730
epoch:   8 	 loss: 18.227 	 return: 45.727 	 ep_len: 45.727
epoch:   9 	 loss: 19.667 	 return: 47.933 	 ep_len: 47.933
epoch:  10 	 loss: 20.882 	 return: 54.793 	 ep_len: 54.793
epoch:  11 	 loss: 21.050 	 return: 56.281 	 ep_len: 56.281
epoch:  12 	 loss: 20.379 	 return: 54.419 	 ep_len: 54.419
epoch:  13 	 loss: 28.754 	 return: 75.000 	 ep_len: 75.000
epoch:  14 	 loss: 27.014 	 return: 70.192 	 ep_len: 70.192
epoch:  15 	 loss: 23.302 	 return: 66.039 	 ep_len: 66.039
epoch:  16 	 loss: 27.332 	 return: 76.194 	 ep_len: 76.194
epoch:  17 	 loss: 27.899 	 return: 78.922 	 ep_len: 78.922
epoch:  18 	 loss: 28.681 	 return: 83.667 	 ep_len: 83.667
epoch:  19 	 loss: 32.392 	 return: 90.246 	 ep_len: 90.246
epoch:  20 	 loss: 33.158 	 return: 96.500 	 ep_len: 96.500
epoch:  21 	 loss: 34.593 	 return: 102.816 	 ep_len: 102.816
epoch:  22 	 loss: 39.281 	 return: 114.636 	 ep_len: 114.636
epoch:  23 	 loss: 49.309 	 return: 141.583 	 ep_len: 141.583
epoch:  24 	 loss: 86.461 	 return: 239.714 	 ep_len: 239.714
epoch:  25 	 loss: 91.765 	 return: 273.579 	 ep_len: 273.579
epoch:  26 	 loss: 104.776 	 return: 328.188 	 ep_len: 328.188
epoch:  27 	 loss: 99.178 	 return: 286.444 	 ep_len: 286.444
epoch:  28 	 loss: 97.297 	 return: 281.842 	 ep_len: 281.842
epoch:  29 	 loss: 102.741 	 return: 325.312 	 ep_len: 325.312
epoch:  30 	 loss: 106.003 	 return: 335.000 	 ep_len: 335.000
epoch:  31 	 loss: 113.203 	 return: 382.857 	 ep_len: 382.857
epoch:  32 	 loss: 121.044 	 return: 429.917 	 ep_len: 429.917
epoch:  33 	 loss: 121.414 	 return: 397.308 	 ep_len: 397.308
epoch:  34 	 loss: 134.054 	 return: 479.182 	 ep_len: 479.182
epoch:  35 	 loss: 122.233 	 return: 418.167 	 ep_len: 418.167
epoch:  36 	 loss: 122.238 	 return: 420.250 	 ep_len: 420.250
epoch:  37 	 loss: 123.408 	 return: 444.167 	 ep_len: 444.167
epoch:  38 	 loss: 136.583 	 return: 499.909 	 ep_len: 499.909
epoch:  39 	 loss: 137.712 	 return: 500.000 	 ep_len: 500.000
epoch:  40 	 loss: 132.680 	 return: 470.455 	 ep_len: 470.455
epoch:  41 	 loss: 136.343 	 return: 500.000 	 ep_len: 500.000
epoch:  42 	 loss: 134.688 	 return: 500.000 	 ep_len: 500.000
epoch:  43 	 loss: 137.182 	 return: 500.000 	 ep_len: 500.000
epoch:  44 	 loss: 134.731 	 return: 488.364 	 ep_len: 488.364
epoch:  45 	 loss: 135.795 	 return: 500.000 	 ep_len: 500.000
epoch:  46 	 loss: 131.883 	 return: 484.818 	 ep_len: 484.818
epoch:  47 	 loss: 135.654 	 return: 500.000 	 ep_len: 500.000
epoch:  48 	 loss: 135.809 	 return: 500.000 	 ep_len: 500.000
epoch:  49 	 loss: 131.698 	 return: 475.545 	 ep_len: 475.545
epoch:  50 	 loss: 128.795 	 return: 465.091 	 ep_len: 465.091
epoch:  51 	 loss: 110.678 	 return: 398.000 	 ep_len: 398.000
epoch:  52 	 loss: 102.360 	 return: 364.357 	 ep_len: 364.357
epoch:  53 	 loss: 84.682 	 return: 307.471 	 ep_len: 307.471
epoch:  54 	 loss: 80.365 	 return: 289.833 	 ep_len: 289.833
epoch:  55 	 loss: 78.512 	 return: 280.722 	 ep_len: 280.722
epoch:  56 	 loss: 77.950 	 return: 274.895 	 ep_len: 274.895
epoch:  57 	 loss: 86.366 	 return: 299.235 	 ep_len: 299.235
epoch:  58 	 loss: 96.106 	 return: 350.467 	 ep_len: 350.467
epoch:  59 	 loss: 120.001 	 return: 440.250 	 ep_len: 440.250
epoch:  60 	 loss: 130.936 	 return: 479.636 	 ep_len: 479.636
epoch:  61 	 loss: 130.182 	 return: 491.545 	 ep_len: 491.545
epoch:  62 	 loss: 129.307 	 return: 470.000 	 ep_len: 470.000
epoch:  63 	 loss: 132.824 	 return: 500.000 	 ep_len: 500.000
epoch:  64 	 loss: 127.337 	 return: 466.000 	 ep_len: 466.000
epoch:  65 	 loss: 121.348 	 return: 417.308 	 ep_len: 417.308
epoch:  66 	 loss: 126.545 	 return: 475.455 	 ep_len: 475.455
epoch:  67 	 loss: 127.601 	 return: 484.909 	 ep_len: 484.909
epoch:  68 	 loss: 118.572 	 return: 449.917 	 ep_len: 449.917
epoch:  69 	 loss: 125.631 	 return: 500.000 	 ep_len: 500.000
epoch:  70 	 loss: 124.287 	 return: 482.455 	 ep_len: 482.455
epoch:  71 	 loss: 123.768 	 return: 494.455 	 ep_len: 494.455
epoch:  72 	 loss: 125.009 	 return: 500.000 	 ep_len: 500.000
epoch:  73 	 loss: 124.539 	 return: 468.455 	 ep_len: 468.455
epoch:  74 	 loss: 126.240 	 return: 500.000 	 ep_len: 500.000
epoch:  75 	 loss: 126.028 	 return: 500.000 	 ep_len: 500.000
epoch:  76 	 loss: 120.869 	 return: 456.455 	 ep_len: 456.455
epoch:  77 	 loss: 119.810 	 return: 451.667 	 ep_len: 451.667
epoch:  78 	 loss: 113.986 	 return: 419.692 	 ep_len: 419.692
epoch:  79 	 loss: 124.604 	 return: 489.818 	 ep_len: 489.818
epoch:  80 	 loss: 125.983 	 return: 492.091 	 ep_len: 492.091
epoch:  81 	 loss: 119.186 	 return: 451.417 	 ep_len: 451.417
epoch:  82 	 loss: 122.318 	 return: 476.545 	 ep_len: 476.545
epoch:  83 	 loss: 124.931 	 return: 476.818 	 ep_len: 476.818
epoch:  84 	 loss: 126.483 	 return: 470.455 	 ep_len: 470.455
epoch:  85 	 loss: 128.760 	 return: 500.000 	 ep_len: 500.000
epoch:  86 	 loss: 127.450 	 return: 499.273 	 ep_len: 499.273
epoch:  87 	 loss: 124.280 	 return: 459.273 	 ep_len: 459.273
epoch:  88 	 loss: 127.955 	 return: 500.000 	 ep_len: 500.000
epoch:  89 	 loss: 126.328 	 return: 500.000 	 ep_len: 500.000
epoch:  90 	 loss: 126.277 	 return: 500.000 	 ep_len: 500.000
epoch:  91 	 loss: 124.419 	 return: 487.364 	 ep_len: 487.364
epoch:  92 	 loss: 125.818 	 return: 497.091 	 ep_len: 497.091
epoch:  93 	 loss: 121.392 	 return: 470.364 	 ep_len: 470.364
epoch:  94 	 loss: 124.848 	 return: 497.091 	 ep_len: 497.091
epoch:  95 	 loss: 125.614 	 return: 500.000 	 ep_len: 500.000
epoch:  96 	 loss: 124.293 	 return: 500.000 	 ep_len: 500.000
epoch:  97 	 loss: 119.638 	 return: 485.182 	 ep_len: 485.182
epoch:  98 	 loss: 124.060 	 return: 500.000 	 ep_len: 500.000
epoch:  99 	 loss: 124.501 	 return: 500.000 	 ep_len: 500.000
epoch: 100 	 loss: 124.156 	 return: 500.000 	 ep_len: 500.000
/Users/Matthew/PycharmProjects/CS6955_A5/reward_to_go.py:110: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:256.)
  batch_loss = compute_loss(obs=torch.as_tensor(batch_obs, dtype=torch.float32),
/Users/Matthew/PycharmProjects/CS6955_A5/reward_to_go.py:124: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.
Consider using tensor.detach() first. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:837.)
  print('epoch: %3d \t loss: %.3f \t return: %.3f \t ep_len: %.3f'%

=== Run 2 ===

Using simplest formulation of policy gradient.

epoch:   0 	 loss: 9.772 	 return: 21.528 	 ep_len: 21.528
epoch:   1 	 loss: 10.120 	 return: 22.565 	 ep_len: 22.565
epoch:   2 	 loss: 12.962 	 return: 27.266 	 ep_len: 27.266
epoch:   3 	 loss: 14.002 	 return: 29.398 	 ep_len: 29.398
epoch:   4 	 loss: 15.547 	 return: 32.688 	 ep_len: 32.688
epoch:   5 	 loss: 15.722 	 return: 33.873 	 ep_len: 33.873
epoch:   6 	 loss: 17.332 	 return: 38.783 	 ep_len: 38.783
epoch:   7 	 loss: 20.086 	 return: 45.198 	 ep_len: 45.198
epoch:   8 	 loss: 19.661 	 return: 47.679 	 ep_len: 47.679
epoch:   9 	 loss: 20.492 	 return: 50.440 	 ep_len: 50.440
epoch:  10 	 loss: 23.202 	 return: 54.533 	 ep_len: 54.533
epoch:  11 	 loss: 21.751 	 return: 57.284 	 ep_len: 57.284
epoch:  12 	 loss: 20.386 	 return: 55.000 	 ep_len: 55.000
epoch:  13 	 loss: 23.741 	 return: 65.442 	 ep_len: 65.442
epoch:  14 	 loss: 25.546 	 return: 70.479 	 ep_len: 70.479
epoch:  15 	 loss: 28.112 	 return: 74.338 	 ep_len: 74.338
epoch:  16 	 loss: 28.057 	 return: 78.077 	 ep_len: 78.077
epoch:  17 	 loss: 30.898 	 return: 86.483 	 ep_len: 86.483
epoch:  18 	 loss: 37.122 	 return: 107.426 	 ep_len: 107.426
epoch:  19 	 loss: 36.274 	 return: 109.043 	 ep_len: 109.043
epoch:  20 	 loss: 41.688 	 return: 121.762 	 ep_len: 121.762
epoch:  21 	 loss: 39.625 	 return: 123.732 	 ep_len: 123.732
epoch:  22 	 loss: 40.621 	 return: 128.897 	 ep_len: 128.897
epoch:  23 	 loss: 41.534 	 return: 134.605 	 ep_len: 134.605
epoch:  24 	 loss: 48.319 	 return: 147.676 	 ep_len: 147.676
epoch:  25 	 loss: 53.214 	 return: 168.800 	 ep_len: 168.800
epoch:  26 	 loss: 56.194 	 return: 172.966 	 ep_len: 172.966
epoch:  27 	 loss: 62.094 	 return: 193.000 	 ep_len: 193.000
epoch:  28 	 loss: 81.558 	 return: 242.091 	 ep_len: 242.091
epoch:  29 	 loss: 92.098 	 return: 296.353 	 ep_len: 296.353
epoch:  30 	 loss: 91.852 	 return: 300.118 	 ep_len: 300.118
epoch:  31 	 loss: 80.882 	 return: 278.737 	 ep_len: 278.737
epoch:  32 	 loss: 82.854 	 return: 264.368 	 ep_len: 264.368
epoch:  33 	 loss: 97.687 	 return: 334.867 	 ep_len: 334.867
epoch:  34 	 loss: 112.847 	 return: 390.308 	 ep_len: 390.308
epoch:  35 	 loss: 115.864 	 return: 430.250 	 ep_len: 430.250
epoch:  36 	 loss: 122.537 	 return: 461.000 	 ep_len: 461.000
epoch:  37 	 loss: 124.951 	 return: 476.000 	 ep_len: 476.000
epoch:  38 	 loss: 116.911 	 return: 435.833 	 ep_len: 435.833
epoch:  39 	 loss: 120.695 	 return: 457.182 	 ep_len: 457.182
epoch:  40 	 loss: 118.989 	 return: 456.000 	 ep_len: 456.000
epoch:  41 	 loss: 120.870 	 return: 457.667 	 ep_len: 457.667
epoch:  42 	 loss: 119.033 	 return: 457.083 	 ep_len: 457.083
epoch:  43 	 loss: 118.614 	 return: 468.273 	 ep_len: 468.273
epoch:  44 	 loss: 122.632 	 return: 492.091 	 ep_len: 492.091
epoch:  45 	 loss: 122.228 	 return: 495.364 	 ep_len: 495.364
epoch:  46 	 loss: 118.151 	 return: 490.909 	 ep_len: 490.909
epoch:  47 	 loss: 122.806 	 return: 500.000 	 ep_len: 500.000
epoch:  48 	 loss: 121.184 	 return: 500.000 	 ep_len: 500.000
epoch:  49 	 loss: 121.760 	 return: 500.000 	 ep_len: 500.000
epoch:  50 	 loss: 118.492 	 return: 478.182 	 ep_len: 478.182
epoch:  51 	 loss: 118.380 	 return: 490.636 	 ep_len: 490.636
epoch:  52 	 loss: 119.464 	 return: 500.000 	 ep_len: 500.000
epoch:  53 	 loss: 110.402 	 return: 457.091 	 ep_len: 457.091
epoch:  54 	 loss: 115.445 	 return: 484.818 	 ep_len: 484.818
epoch:  55 	 loss: 114.020 	 return: 483.091 	 ep_len: 483.091
epoch:  56 	 loss: 114.732 	 return: 481.818 	 ep_len: 481.818
epoch:  57 	 loss: 111.546 	 return: 476.727 	 ep_len: 476.727
epoch:  58 	 loss: 111.303 	 return: 476.818 	 ep_len: 476.818
epoch:  59 	 loss: 115.717 	 return: 494.364 	 ep_len: 494.364
epoch:  60 	 loss: 112.886 	 return: 481.000 	 ep_len: 481.000
epoch:  61 	 loss: 117.250 	 return: 500.000 	 ep_len: 500.000
epoch:  62 	 loss: 113.894 	 return: 489.909 	 ep_len: 489.909
epoch:  63 	 loss: 112.482 	 return: 481.000 	 ep_len: 481.000
epoch:  64 	 loss: 115.056 	 return: 488.545 	 ep_len: 488.545
epoch:  65 	 loss: 114.069 	 return: 480.091 	 ep_len: 480.091
epoch:  66 	 loss: 118.169 	 return: 500.000 	 ep_len: 500.000
epoch:  67 	 loss: 119.696 	 return: 499.273 	 ep_len: 499.273
epoch:  68 	 loss: 113.002 	 return: 473.818 	 ep_len: 473.818
epoch:  69 	 loss: 115.337 	 return: 500.000 	 ep_len: 500.000
epoch:  70 	 loss: 114.623 	 return: 475.455 	 ep_len: 475.455
epoch:  71 	 loss: 116.884 	 return: 500.000 	 ep_len: 500.000
epoch:  72 	 loss: 117.008 	 return: 500.000 	 ep_len: 500.000
epoch:  73 	 loss: 117.480 	 return: 500.000 	 ep_len: 500.000
epoch:  74 	 loss: 116.501 	 return: 500.000 	 ep_len: 500.000
epoch:  75 	 loss: 115.949 	 return: 500.000 	 ep_len: 500.000
epoch:  76 	 loss: 115.449 	 return: 497.182 	 ep_len: 497.182
epoch:  77 	 loss: 112.615 	 return: 491.182 	 ep_len: 491.182
epoch:  78 	 loss: 113.371 	 return: 500.000 	 ep_len: 500.000
epoch:  79 	 loss: 112.352 	 return: 489.000 	 ep_len: 489.000
epoch:  80 	 loss: 109.754 	 return: 467.727 	 ep_len: 467.727
epoch:  81 	 loss: 112.610 	 return: 497.909 	 ep_len: 497.909
epoch:  82 	 loss: 111.629 	 return: 500.000 	 ep_len: 500.000
epoch:  83 	 loss: 113.287 	 return: 500.000 	 ep_len: 500.000
epoch:  84 	 loss: 108.705 	 return: 500.000 	 ep_len: 500.000
epoch:  85 	 loss: 109.150 	 return: 470.636 	 ep_len: 470.636
epoch:  86 	 loss: 109.987 	 return: 499.636 	 ep_len: 499.636
epoch:  87 	 loss: 109.112 	 return: 500.000 	 ep_len: 500.000
epoch:  88 	 loss: 108.534 	 return: 500.000 	 ep_len: 500.000
epoch:  89 	 loss: 104.992 	 return: 484.455 	 ep_len: 484.455
epoch:  90 	 loss: 105.968 	 return: 481.818 	 ep_len: 481.818
epoch:  91 	 loss: 108.627 	 return: 494.727 	 ep_len: 494.727
epoch:  92 	 loss: 105.657 	 return: 492.455 	 ep_len: 492.455
epoch:  93 	 loss: 103.112 	 return: 433.333 	 ep_len: 433.333
epoch:  94 	 loss: 102.955 	 return: 455.167 	 ep_len: 455.167
epoch:  95 	 loss: 93.039 	 return: 391.308 	 ep_len: 391.308
epoch:  96 	 loss: 90.349 	 return: 358.357 	 ep_len: 358.357
epoch:  97 	 loss: 87.472 	 return: 365.286 	 ep_len: 365.286
epoch:  98 	 loss: 90.316 	 return: 371.643 	 ep_len: 371.643
epoch:  99 	 loss: 97.449 	 return: 426.833 	 ep_len: 426.833
epoch: 100 	 loss: 98.803 	 return: 428.417 	 ep_len: 428.417
/Users/Matthew/PycharmProjects/CS6955_A5/reward_to_go.py:110: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:256.)
  batch_loss = compute_loss(obs=torch.as_tensor(batch_obs, dtype=torch.float32),
/Users/Matthew/PycharmProjects/CS6955_A5/reward_to_go.py:124: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.
Consider using tensor.detach() first. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:837.)
  print('epoch: %3d \t loss: %.3f \t return: %.3f \t ep_len: %.3f'%

=== Run 3 ===

Using simplest formulation of policy gradient.

epoch:   0 	 loss: 10.536 	 return: 22.954 	 ep_len: 22.954
epoch:   1 	 loss: 11.160 	 return: 25.396 	 ep_len: 25.396
epoch:   2 	 loss: 12.663 	 return: 27.527 	 ep_len: 27.527
epoch:   3 	 loss: 12.410 	 return: 28.441 	 ep_len: 28.441
epoch:   4 	 loss: 14.978 	 return: 34.143 	 ep_len: 34.143
epoch:   5 	 loss: 15.675 	 return: 35.408 	 ep_len: 35.408
epoch:   6 	 loss: 15.634 	 return: 39.352 	 ep_len: 39.352
epoch:   7 	 loss: 18.430 	 return: 41.892 	 ep_len: 41.892
epoch:   8 	 loss: 17.346 	 return: 44.175 	 ep_len: 44.175
epoch:   9 	 loss: 15.518 	 return: 42.846 	 ep_len: 42.846
epoch:  10 	 loss: 17.288 	 return: 46.935 	 ep_len: 46.935
epoch:  11 	 loss: 17.024 	 return: 46.822 	 ep_len: 46.822
epoch:  12 	 loss: 19.422 	 return: 54.215 	 ep_len: 54.215
epoch:  13 	 loss: 17.833 	 return: 49.107 	 ep_len: 49.107
epoch:  14 	 loss: 19.081 	 return: 55.220 	 ep_len: 55.220
epoch:  15 	 loss: 18.897 	 return: 55.209 	 ep_len: 55.209
epoch:  16 	 loss: 21.061 	 return: 62.987 	 ep_len: 62.987
epoch:  17 	 loss: 21.006 	 return: 59.929 	 ep_len: 59.929
epoch:  18 	 loss: 20.867 	 return: 61.659 	 ep_len: 61.659
epoch:  19 	 loss: 21.709 	 return: 65.364 	 ep_len: 65.364
epoch:  20 	 loss: 20.773 	 return: 65.260 	 ep_len: 65.260
epoch:  21 	 loss: 23.077 	 return: 73.600 	 ep_len: 73.600
epoch:  22 	 loss: 22.992 	 return: 71.451 	 ep_len: 71.451
epoch:  23 	 loss: 23.967 	 return: 76.833 	 ep_len: 76.833
epoch:  24 	 loss: 26.354 	 return: 83.400 	 ep_len: 83.400
epoch:  25 	 loss: 27.063 	 return: 84.283 	 ep_len: 84.283
epoch:  26 	 loss: 27.269 	 return: 87.397 	 ep_len: 87.397
epoch:  27 	 loss: 31.999 	 return: 103.245 	 ep_len: 103.245
epoch:  28 	 loss: 37.211 	 return: 117.163 	 ep_len: 117.163
epoch:  29 	 loss: 36.330 	 return: 114.711 	 ep_len: 114.711
epoch:  30 	 loss: 39.604 	 return: 137.162 	 ep_len: 137.162
epoch:  31 	 loss: 44.788 	 return: 151.576 	 ep_len: 151.576
epoch:  32 	 loss: 50.215 	 return: 174.552 	 ep_len: 174.552
epoch:  33 	 loss: 46.032 	 return: 158.438 	 ep_len: 158.438
epoch:  34 	 loss: 46.998 	 return: 164.484 	 ep_len: 164.484
epoch:  35 	 loss: 54.102 	 return: 189.481 	 ep_len: 189.481
epoch:  36 	 loss: 62.202 	 return: 208.958 	 ep_len: 208.958
epoch:  37 	 loss: 64.667 	 return: 217.333 	 ep_len: 217.333
epoch:  38 	 loss: 79.538 	 return: 246.524 	 ep_len: 246.524
epoch:  39 	 loss: 81.048 	 return: 257.700 	 ep_len: 257.700
epoch:  40 	 loss: 102.110 	 return: 351.200 	 ep_len: 351.200
epoch:  41 	 loss: 120.743 	 return: 428.083 	 ep_len: 428.083
epoch:  42 	 loss: 122.563 	 return: 462.364 	 ep_len: 462.364
epoch:  43 	 loss: 113.479 	 return: 410.615 	 ep_len: 410.615
epoch:  44 	 loss: 105.610 	 return: 392.429 	 ep_len: 392.429
epoch:  45 	 loss: 119.604 	 return: 434.917 	 ep_len: 434.917
epoch:  46 	 loss: 129.122 	 return: 480.364 	 ep_len: 480.364
epoch:  47 	 loss: 132.067 	 return: 500.000 	 ep_len: 500.000
epoch:  48 	 loss: 132.522 	 return: 500.000 	 ep_len: 500.000
epoch:  49 	 loss: 133.339 	 return: 500.000 	 ep_len: 500.000
epoch:  50 	 loss: 132.553 	 return: 500.000 	 ep_len: 500.000
epoch:  51 	 loss: 132.711 	 return: 500.000 	 ep_len: 500.000
epoch:  52 	 loss: 130.704 	 return: 498.818 	 ep_len: 498.818
epoch:  53 	 loss: 127.157 	 return: 486.000 	 ep_len: 486.000
epoch:  54 	 loss: 115.714 	 return: 427.167 	 ep_len: 427.167
epoch:  55 	 loss: 107.766 	 return: 388.000 	 ep_len: 388.000
epoch:  56 	 loss: 114.369 	 return: 421.692 	 ep_len: 421.692
epoch:  57 	 loss: 122.218 	 return: 457.273 	 ep_len: 457.273
epoch:  58 	 loss: 132.146 	 return: 500.000 	 ep_len: 500.000
epoch:  59 	 loss: 130.243 	 return: 500.000 	 ep_len: 500.000
epoch:  60 	 loss: 123.031 	 return: 452.167 	 ep_len: 452.167
epoch:  61 	 loss: 126.659 	 return: 471.818 	 ep_len: 471.818
epoch:  62 	 loss: 124.732 	 return: 469.091 	 ep_len: 469.091
epoch:  63 	 loss: 129.591 	 return: 489.818 	 ep_len: 489.818
epoch:  64 	 loss: 124.531 	 return: 459.364 	 ep_len: 459.364
epoch:  65 	 loss: 127.615 	 return: 472.909 	 ep_len: 472.909
epoch:  66 	 loss: 121.899 	 return: 461.182 	 ep_len: 461.182
epoch:  67 	 loss: 125.768 	 return: 473.000 	 ep_len: 473.000
epoch:  68 	 loss: 122.166 	 return: 451.167 	 ep_len: 451.167
epoch:  69 	 loss: 127.422 	 return: 472.818 	 ep_len: 472.818
epoch:  70 	 loss: 124.869 	 return: 489.909 	 ep_len: 489.909
epoch:  71 	 loss: 120.522 	 return: 455.909 	 ep_len: 455.909
epoch:  72 	 loss: 126.120 	 return: 463.727 	 ep_len: 463.727
epoch:  73 	 loss: 121.812 	 return: 445.917 	 ep_len: 445.917
epoch:  74 	 loss: 123.013 	 return: 478.000 	 ep_len: 478.000
epoch:  75 	 loss: 126.577 	 return: 500.000 	 ep_len: 500.000
epoch:  76 	 loss: 127.622 	 return: 500.000 	 ep_len: 500.000
epoch:  77 	 loss: 120.174 	 return: 446.083 	 ep_len: 446.083
epoch:  78 	 loss: 124.075 	 return: 480.455 	 ep_len: 480.455
epoch:  79 	 loss: 130.902 	 return: 500.000 	 ep_len: 500.000
epoch:  80 	 loss: 126.127 	 return: 483.455 	 ep_len: 483.455
epoch:  81 	 loss: 125.399 	 return: 475.273 	 ep_len: 475.273
epoch:  82 	 loss: 126.587 	 return: 478.545 	 ep_len: 478.545
epoch:  83 	 loss: 130.038 	 return: 500.000 	 ep_len: 500.000
epoch:  84 	 loss: 127.662 	 return: 484.727 	 ep_len: 484.727
epoch:  85 	 loss: 126.050 	 return: 482.818 	 ep_len: 482.818
epoch:  86 	 loss: 125.532 	 return: 453.250 	 ep_len: 453.250
epoch:  87 	 loss: 129.678 	 return: 496.909 	 ep_len: 496.909
epoch:  88 	 loss: 129.495 	 return: 477.727 	 ep_len: 477.727
epoch:  89 	 loss: 125.687 	 return: 454.833 	 ep_len: 454.833
epoch:  90 	 loss: 131.725 	 return: 495.455 	 ep_len: 495.455
epoch:  91 	 loss: 125.859 	 return: 447.250 	 ep_len: 447.250
epoch:  92 	 loss: 132.030 	 return: 500.000 	 ep_len: 500.000
epoch:  93 	 loss: 124.163 	 return: 398.538 	 ep_len: 398.538
epoch:  94 	 loss: 132.216 	 return: 500.000 	 ep_len: 500.000
epoch:  95 	 loss: 133.816 	 return: 500.000 	 ep_len: 500.000
epoch:  96 	 loss: 125.623 	 return: 464.909 	 ep_len: 464.909
epoch:  97 	 loss: 128.110 	 return: 465.455 	 ep_len: 465.455
epoch:  98 	 loss: 128.996 	 return: 470.364 	 ep_len: 470.364
epoch:  99 	 loss: 131.014 	 return: 476.091 	 ep_len: 476.091
epoch: 100 	 loss: 127.350 	 return: 471.182 	 ep_len: 471.182
/Users/Matthew/PycharmProjects/CS6955_A5/reward_to_go.py:110: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:256.)
  batch_loss = compute_loss(obs=torch.as_tensor(batch_obs, dtype=torch.float32),
/Users/Matthew/PycharmProjects/CS6955_A5/reward_to_go.py:124: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.
Consider using tensor.detach() first. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:837.)
  print('epoch: %3d \t loss: %.3f \t return: %.3f \t ep_len: %.3f'%

=== Run 4 ===

Using simplest formulation of policy gradient.

epoch:   0 	 loss: 9.481 	 return: 20.433 	 ep_len: 20.433
epoch:   1 	 loss: 10.084 	 return: 22.084 	 ep_len: 22.084
epoch:   2 	 loss: 12.186 	 return: 25.821 	 ep_len: 25.821
epoch:   3 	 loss: 13.242 	 return: 29.604 	 ep_len: 29.604
epoch:   4 	 loss: 17.811 	 return: 37.507 	 ep_len: 37.507
epoch:   5 	 loss: 17.206 	 return: 36.079 	 ep_len: 36.079
epoch:   6 	 loss: 17.503 	 return: 39.449 	 ep_len: 39.449
epoch:   7 	 loss: 20.909 	 return: 48.689 	 ep_len: 48.689
epoch:   8 	 loss: 21.817 	 return: 51.173 	 ep_len: 51.173
epoch:   9 	 loss: 23.138 	 return: 58.011 	 ep_len: 58.011
epoch:  10 	 loss: 22.261 	 return: 54.914 	 ep_len: 54.914
epoch:  11 	 loss: 23.971 	 return: 62.062 	 ep_len: 62.062
epoch:  12 	 loss: 27.397 	 return: 70.789 	 ep_len: 70.789
epoch:  13 	 loss: 37.594 	 return: 100.157 	 ep_len: 100.157
epoch:  14 	 loss: 36.493 	 return: 99.451 	 ep_len: 99.451
epoch:  15 	 loss: 34.028 	 return: 93.667 	 ep_len: 93.667
epoch:  16 	 loss: 37.863 	 return: 103.204 	 ep_len: 103.204
epoch:  17 	 loss: 38.773 	 return: 109.717 	 ep_len: 109.717
epoch:  18 	 loss: 33.740 	 return: 102.327 	 ep_len: 102.327
epoch:  19 	 loss: 39.641 	 return: 123.659 	 ep_len: 123.659
epoch:  20 	 loss: 46.060 	 return: 147.324 	 ep_len: 147.324
epoch:  21 	 loss: 47.932 	 return: 152.818 	 ep_len: 152.818
epoch:  22 	 loss: 46.743 	 return: 143.028 	 ep_len: 143.028
epoch:  23 	 loss: 50.053 	 return: 151.909 	 ep_len: 151.909
epoch:  24 	 loss: 78.507 	 return: 231.500 	 ep_len: 231.500
epoch:  25 	 loss: 86.706 	 return: 269.842 	 ep_len: 269.842
epoch:  26 	 loss: 92.817 	 return: 302.882 	 ep_len: 302.882
epoch:  27 	 loss: 88.693 	 return: 281.056 	 ep_len: 281.056
epoch:  28 	 loss: 88.132 	 return: 296.588 	 ep_len: 296.588
epoch:  29 	 loss: 91.782 	 return: 315.412 	 ep_len: 315.412
epoch:  30 	 loss: 84.731 	 return: 300.706 	 ep_len: 300.706
epoch:  31 	 loss: 100.551 	 return: 342.667 	 ep_len: 342.667
epoch:  32 	 loss: 105.527 	 return: 383.500 	 ep_len: 383.500
epoch:  33 	 loss: 107.502 	 return: 385.154 	 ep_len: 385.154
epoch:  34 	 loss: 113.982 	 return: 403.231 	 ep_len: 403.231
epoch:  35 	 loss: 121.822 	 return: 440.333 	 ep_len: 440.333
epoch:  36 	 loss: 120.797 	 return: 447.833 	 ep_len: 447.833
epoch:  37 	 loss: 121.418 	 return: 436.250 	 ep_len: 436.250
epoch:  38 	 loss: 113.894 	 return: 421.692 	 ep_len: 421.692
epoch:  39 	 loss: 103.182 	 return: 370.357 	 ep_len: 370.357
epoch:  40 	 loss: 102.101 	 return: 366.429 	 ep_len: 366.429
epoch:  41 	 loss: 108.655 	 return: 405.462 	 ep_len: 405.462
epoch:  42 	 loss: 115.892 	 return: 429.000 	 ep_len: 429.000
epoch:  43 	 loss: 125.325 	 return: 476.727 	 ep_len: 476.727
epoch:  44 	 loss: 123.557 	 return: 457.833 	 ep_len: 457.833
epoch:  45 	 loss: 113.545 	 return: 421.154 	 ep_len: 421.154
epoch:  46 	 loss: 121.438 	 return: 440.167 	 ep_len: 440.167
epoch:  47 	 loss: 122.915 	 return: 447.667 	 ep_len: 447.667
epoch:  48 	 loss: 113.164 	 return: 383.643 	 ep_len: 383.643
epoch:  49 	 loss: 120.412 	 return: 428.833 	 ep_len: 428.833
epoch:  50 	 loss: 108.747 	 return: 397.077 	 ep_len: 397.077
epoch:  51 	 loss: 94.129 	 return: 346.133 	 ep_len: 346.133
epoch:  52 	 loss: 91.727 	 return: 327.438 	 ep_len: 327.438
epoch:  53 	 loss: 87.905 	 return: 312.235 	 ep_len: 312.235
epoch:  54 	 loss: 97.088 	 return: 357.929 	 ep_len: 357.929
epoch:  55 	 loss: 113.427 	 return: 417.250 	 ep_len: 417.250
epoch:  56 	 loss: 122.643 	 return: 457.667 	 ep_len: 457.667
epoch:  57 	 loss: 126.582 	 return: 479.273 	 ep_len: 479.273
epoch:  58 	 loss: 126.008 	 return: 487.364 	 ep_len: 487.364
epoch:  59 	 loss: 124.324 	 return: 480.182 	 ep_len: 480.182
epoch:  60 	 loss: 120.284 	 return: 454.083 	 ep_len: 454.083
epoch:  61 	 loss: 121.245 	 return: 483.727 	 ep_len: 483.727
epoch:  62 	 loss: 124.717 	 return: 500.000 	 ep_len: 500.000
epoch:  63 	 loss: 121.161 	 return: 485.636 	 ep_len: 485.636
epoch:  64 	 loss: 118.870 	 return: 466.636 	 ep_len: 466.636
epoch:  65 	 loss: 118.347 	 return: 461.636 	 ep_len: 461.636
epoch:  66 	 loss: 121.257 	 return: 489.273 	 ep_len: 489.273
epoch:  67 	 loss: 118.644 	 return: 447.667 	 ep_len: 447.667
epoch:  68 	 loss: 123.157 	 return: 498.545 	 ep_len: 498.545
epoch:  69 	 loss: 117.730 	 return: 455.364 	 ep_len: 455.364
epoch:  70 	 loss: 118.523 	 return: 450.083 	 ep_len: 450.083
epoch:  71 	 loss: 121.568 	 return: 476.455 	 ep_len: 476.455
epoch:  72 	 loss: 119.509 	 return: 474.364 	 ep_len: 474.364
epoch:  73 	 loss: 121.379 	 return: 486.909 	 ep_len: 486.909
epoch:  74 	 loss: 119.283 	 return: 441.083 	 ep_len: 441.083
epoch:  75 	 loss: 122.369 	 return: 473.636 	 ep_len: 473.636
epoch:  76 	 loss: 118.540 	 return: 450.250 	 ep_len: 450.250
epoch:  77 	 loss: 123.592 	 return: 471.636 	 ep_len: 471.636
epoch:  78 	 loss: 119.403 	 return: 437.167 	 ep_len: 437.167
epoch:  79 	 loss: 124.003 	 return: 500.000 	 ep_len: 500.000
epoch:  80 	 loss: 117.628 	 return: 442.583 	 ep_len: 442.583
epoch:  81 	 loss: 124.797 	 return: 500.000 	 ep_len: 500.000
epoch:  82 	 loss: 124.795 	 return: 500.000 	 ep_len: 500.000
epoch:  83 	 loss: 125.108 	 return: 500.000 	 ep_len: 500.000
epoch:  84 	 loss: 125.285 	 return: 456.455 	 ep_len: 456.455
epoch:  85 	 loss: 125.727 	 return: 500.000 	 ep_len: 500.000
epoch:  86 	 loss: 125.335 	 return: 500.000 	 ep_len: 500.000
epoch:  87 	 loss: 117.964 	 return: 466.182 	 ep_len: 466.182
epoch:  88 	 loss: 94.729 	 return: 360.267 	 ep_len: 360.267
epoch:  89 	 loss: 79.168 	 return: 315.529 	 ep_len: 315.529
epoch:  90 	 loss: 75.938 	 return: 292.056 	 ep_len: 292.056
epoch:  91 	 loss: 70.528 	 return: 278.056 	 ep_len: 278.056
epoch:  92 	 loss: 69.335 	 return: 246.476 	 ep_len: 246.476
epoch:  93 	 loss: 64.737 	 return: 257.450 	 ep_len: 257.450
epoch:  94 	 loss: 68.268 	 return: 265.300 	 ep_len: 265.300
epoch:  95 	 loss: 78.009 	 return: 300.882 	 ep_len: 300.882
epoch:  96 	 loss: 87.036 	 return: 317.375 	 ep_len: 317.375
epoch:  97 	 loss: 122.978 	 return: 451.750 	 ep_len: 451.750
epoch:  98 	 loss: 124.041 	 return: 454.417 	 ep_len: 454.417
epoch:  99 	 loss: 122.942 	 return: 462.545 	 ep_len: 462.545
epoch: 100 	 loss: 122.465 	 return: 449.167 	 ep_len: 449.167
/Users/Matthew/PycharmProjects/CS6955_A5/reward_to_go.py:110: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:256.)
  batch_loss = compute_loss(obs=torch.as_tensor(batch_obs, dtype=torch.float32),
/Users/Matthew/PycharmProjects/CS6955_A5/reward_to_go.py:124: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.
Consider using tensor.detach() first. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:837.)
  print('epoch: %3d \t loss: %.3f \t return: %.3f \t ep_len: %.3f'%

=== Run 5 ===

Using simplest formulation of policy gradient.

epoch:   0 	 loss: 7.375 	 return: 17.051 	 ep_len: 17.051
epoch:   1 	 loss: 8.830 	 return: 19.728 	 ep_len: 19.728
epoch:   2 	 loss: 8.917 	 return: 20.382 	 ep_len: 20.382
epoch:   3 	 loss: 10.860 	 return: 23.349 	 ep_len: 23.349
epoch:   4 	 loss: 12.850 	 return: 26.925 	 ep_len: 26.925
epoch:   5 	 loss: 13.166 	 return: 28.799 	 ep_len: 28.799
epoch:   6 	 loss: 15.079 	 return: 32.265 	 ep_len: 32.265
epoch:   7 	 loss: 12.811 	 return: 30.370 	 ep_len: 30.370
epoch:   8 	 loss: 15.280 	 return: 33.351 	 ep_len: 33.351
epoch:   9 	 loss: 16.356 	 return: 37.797 	 ep_len: 37.797
epoch:  10 	 loss: 19.108 	 return: 44.336 	 ep_len: 44.336
epoch:  11 	 loss: 17.654 	 return: 44.407 	 ep_len: 44.407
epoch:  12 	 loss: 18.213 	 return: 46.110 	 ep_len: 46.110
epoch:  13 	 loss: 15.936 	 return: 41.405 	 ep_len: 41.405
epoch:  14 	 loss: 18.070 	 return: 48.583 	 ep_len: 48.583
epoch:  15 	 loss: 19.526 	 return: 51.704 	 ep_len: 51.704
epoch:  16 	 loss: 17.518 	 return: 47.981 	 ep_len: 47.981
epoch:  17 	 loss: 21.714 	 return: 56.852 	 ep_len: 56.852
epoch:  18 	 loss: 20.343 	 return: 55.667 	 ep_len: 55.667
epoch:  19 	 loss: 22.353 	 return: 61.976 	 ep_len: 61.976
epoch:  20 	 loss: 20.738 	 return: 59.738 	 ep_len: 59.738
epoch:  21 	 loss: 23.204 	 return: 66.867 	 ep_len: 66.867
epoch:  22 	 loss: 23.034 	 return: 64.936 	 ep_len: 64.936
epoch:  23 	 loss: 23.947 	 return: 68.658 	 ep_len: 68.658
epoch:  24 	 loss: 23.767 	 return: 69.847 	 ep_len: 69.847
epoch:  25 	 loss: 28.469 	 return: 80.677 	 ep_len: 80.677
epoch:  26 	 loss: 27.283 	 return: 76.000 	 ep_len: 76.000
epoch:  27 	 loss: 28.900 	 return: 88.298 	 ep_len: 88.298
epoch:  28 	 loss: 33.629 	 return: 98.096 	 ep_len: 98.096
epoch:  29 	 loss: 34.383 	 return: 95.887 	 ep_len: 95.887
epoch:  30 	 loss: 37.030 	 return: 113.689 	 ep_len: 113.689
epoch:  31 	 loss: 42.588 	 return: 135.395 	 ep_len: 135.395
epoch:  32 	 loss: 45.700 	 return: 137.892 	 ep_len: 137.892
epoch:  33 	 loss: 48.710 	 return: 154.667 	 ep_len: 154.667
epoch:  34 	 loss: 51.961 	 return: 161.156 	 ep_len: 161.156
epoch:  35 	 loss: 51.681 	 return: 158.062 	 ep_len: 158.062
epoch:  36 	 loss: 58.250 	 return: 188.852 	 ep_len: 188.852
epoch:  37 	 loss: 69.709 	 return: 212.042 	 ep_len: 212.042
epoch:  38 	 loss: 74.620 	 return: 239.955 	 ep_len: 239.955
epoch:  39 	 loss: 87.401 	 return: 272.368 	 ep_len: 272.368
epoch:  40 	 loss: 110.262 	 return: 355.733 	 ep_len: 355.733
epoch:  41 	 loss: 120.515 	 return: 388.231 	 ep_len: 388.231
epoch:  42 	 loss: 119.590 	 return: 389.286 	 ep_len: 389.286
epoch:  43 	 loss: 121.332 	 return: 419.333 	 ep_len: 419.333
epoch:  44 	 loss: 126.971 	 return: 457.083 	 ep_len: 457.083
epoch:  45 	 loss: 116.102 	 return: 386.615 	 ep_len: 386.615
epoch:  46 	 loss: 107.264 	 return: 365.071 	 ep_len: 365.071
epoch:  47 	 loss: 123.538 	 return: 433.583 	 ep_len: 433.583
epoch:  48 	 loss: 131.340 	 return: 461.909 	 ep_len: 461.909
epoch:  49 	 loss: 132.318 	 return: 466.091 	 ep_len: 466.091
epoch:  50 	 loss: 130.780 	 return: 424.667 	 ep_len: 424.667
epoch:  51 	 loss: 137.945 	 return: 484.182 	 ep_len: 484.182
epoch:  52 	 loss: 125.700 	 return: 406.769 	 ep_len: 406.769
epoch:  53 	 loss: 134.573 	 return: 439.917 	 ep_len: 439.917
epoch:  54 	 loss: 113.595 	 return: 344.400 	 ep_len: 344.400
epoch:  55 	 loss: 122.213 	 return: 386.571 	 ep_len: 386.571
epoch:  56 	 loss: 136.192 	 return: 440.417 	 ep_len: 440.417
epoch:  57 	 loss: 127.604 	 return: 418.333 	 ep_len: 418.333
epoch:  58 	 loss: 132.038 	 return: 418.167 	 ep_len: 418.167
epoch:  59 	 loss: 125.055 	 return: 379.929 	 ep_len: 379.929
epoch:  60 	 loss: 134.952 	 return: 463.455 	 ep_len: 463.455
epoch:  61 	 loss: 138.346 	 return: 476.000 	 ep_len: 476.000
epoch:  62 	 loss: 140.147 	 return: 499.455 	 ep_len: 499.455
epoch:  63 	 loss: 137.735 	 return: 471.091 	 ep_len: 471.091
epoch:  64 	 loss: 137.805 	 return: 500.000 	 ep_len: 500.000
epoch:  65 	 loss: 136.405 	 return: 500.000 	 ep_len: 500.000
epoch:  66 	 loss: 135.493 	 return: 500.000 	 ep_len: 500.000
epoch:  67 	 loss: 136.542 	 return: 490.455 	 ep_len: 490.455
epoch:  68 	 loss: 105.699 	 return: 385.071 	 ep_len: 385.071
epoch:  69 	 loss: 90.047 	 return: 326.750 	 ep_len: 326.750
epoch:  70 	 loss: 79.506 	 return: 285.167 	 ep_len: 285.167
epoch:  71 	 loss: 74.313 	 return: 274.105 	 ep_len: 274.105
epoch:  72 	 loss: 74.862 	 return: 270.158 	 ep_len: 270.158
epoch:  73 	 loss: 81.056 	 return: 301.000 	 ep_len: 301.000
epoch:  74 	 loss: 89.740 	 return: 314.625 	 ep_len: 314.625
epoch:  75 	 loss: 109.865 	 return: 398.769 	 ep_len: 398.769
epoch:  76 	 loss: 124.603 	 return: 465.545 	 ep_len: 465.545
epoch:  77 	 loss: 127.940 	 return: 490.273 	 ep_len: 490.273
epoch:  78 	 loss: 128.531 	 return: 500.000 	 ep_len: 500.000
epoch:  79 	 loss: 129.162 	 return: 500.000 	 ep_len: 500.000
epoch:  80 	 loss: 129.029 	 return: 500.000 	 ep_len: 500.000
epoch:  81 	 loss: 127.163 	 return: 500.000 	 ep_len: 500.000
epoch:  82 	 loss: 127.465 	 return: 500.000 	 ep_len: 500.000
epoch:  83 	 loss: 126.333 	 return: 500.000 	 ep_len: 500.000
epoch:  84 	 loss: 126.623 	 return: 500.000 	 ep_len: 500.000
epoch:  85 	 loss: 125.627 	 return: 500.000 	 ep_len: 500.000
epoch:  86 	 loss: 125.345 	 return: 500.000 	 ep_len: 500.000
epoch:  87 	 loss: 124.363 	 return: 500.000 	 ep_len: 500.000
epoch:  88 	 loss: 125.318 	 return: 500.000 	 ep_len: 500.000
epoch:  89 	 loss: 124.604 	 return: 500.000 	 ep_len: 500.000
epoch:  90 	 loss: 121.552 	 return: 500.000 	 ep_len: 500.000
epoch:  91 	 loss: 120.612 	 return: 474.909 	 ep_len: 474.909
epoch:  92 	 loss: 122.895 	 return: 500.000 	 ep_len: 500.000
epoch:  93 	 loss: 123.208 	 return: 500.000 	 ep_len: 500.000
epoch:  94 	 loss: 124.210 	 return: 500.000 	 ep_len: 500.000
epoch:  95 	 loss: 124.687 	 return: 500.000 	 ep_len: 500.000
epoch:  96 	 loss: 121.884 	 return: 500.000 	 ep_len: 500.000
epoch:  97 	 loss: 123.882 	 return: 500.000 	 ep_len: 500.000
epoch:  98 	 loss: 122.954 	 return: 500.000 	 ep_len: 500.000
epoch:  99 	 loss: 123.894 	 return: 500.000 	 ep_len: 500.000
epoch: 100 	 loss: 123.019 	 return: 500.000 	 ep_len: 500.000
/Users/Matthew/PycharmProjects/CS6955_A5/reward_to_go.py:110: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:256.)
  batch_loss = compute_loss(obs=torch.as_tensor(batch_obs, dtype=torch.float32),
/Users/Matthew/PycharmProjects/CS6955_A5/reward_to_go.py:124: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.
Consider using tensor.detach() first. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:837.)
  print('epoch: %3d \t loss: %.3f \t return: %.3f \t ep_len: %.3f'%

